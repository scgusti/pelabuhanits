# -*- coding: utf-8 -*-
"""Copy of Proyek_2_Machine_Learning_Terapan_ContentBased_Recomended_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LVcXkUmITPR0Tdren10xZiBH79m1pyvo

# **Import Librrary**
"""

!pip install mplcyberpunk
import numpy as np
import matplotlib.pyplot as plt
import mplcyberpunk
plt.style.use("cyberpunk")
import pandas as pd
import warnings
warnings.filterwarnings('ignore')
from datetime import datetime

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances

from google.colab import files
files.upload()

"""# **Data Collection**"""

!kaggle datasets download -d tmdb/tmdb-movie-metadata
!unzip /content/tmdb-movie-metadata.zip

"""## Checking large data in All Dataset that have been collected"""

credits_df=pd.read_csv('tmdb_5000_credits.csv')
movies_df=pd.read_csv('tmdb_5000_movies.csv')

print('Jumlah data credits: ', len(credits_df))
print('Jumlah data movies: ', len(movies_df))

"""## Checking information in dataset `credits_df`"""

credits_df.info()

"""## Cheking shape data in dataset `credits_df`"""

credits_df.shape

"""## Cheking null value in dataset `credits_df`"""

credits_df.isnull().sum()

"""## Cheking information variabel dataset `movies_df`"""

movies_df.info()

"""## Cheking shape data in dataset `movies_df`"""

movies_df.shape

"""## Checking null value in dataset `movies_df`"""

movies_df.isnull().sum()

"""# **Data Preparation**

## Handling null value in dataset `movies_df`
"""

movies_df['homepage'].fillna('', inplace=True)
movies_df['runtime'].fillna(movies_df['runtime'].mean(), inplace=True)
movies_df['tagline'].fillna('', inplace=True)
movies_df['release_date'].fillna(datetime.now().strftime('%Y-%m-%d'), inplace=True)
movies_df['overview'].fillna('', inplace=True)

print("\nNull values after handling:")
movies_df.isnull().sum()

"""## Marge data Id, tittle, cast and crew Columns on `credits_d` add into `movies_df`"""

credits_df.columns = ['id','tittle','cast','crew']
movies_df= movies_df.merge(credits_df,on='id')

movies_df.head(5)

"""## Checking how many variation genres in dataset movie can relateable"""

i = 1
for idx, name in enumerate(movies_df['genres'].value_counts().index.tolist()):
    if(i==51): break
    print(i)
    print('Name :', name)
    print('Counts :', movies_df['genres'].value_counts()[idx])
    print('---'*8)
    i+=1

"""# **Demographic Filtering**

First started with :
- calculate matric to score or rate a movie
- calculate the score for every movie
- sort the scores and recommend the best rated movie to the users

We can use the average ratings of the movie as the score but using this won't be fair enough since a movie with 8.9 average rating and only 3 votes cannot be considered better than the movie with 7.8 as as average rating but 40 votes.
So, I'll be using **IMDB's Weighted Rating** $\left(WR\right)$  which is given as this below equation:

$$
\text{Weighted Rating (WR)} = \left( \frac{v}{v+m} \cdot R \right) + \left( \frac{m}{v+m} \cdot C \right)
$$


where,
* $v$ = the number of votes for the movie
* $m$ = the minimum votes required to be listed in the chart
* $R$ = the average rating of the movie
* $C$ = the mean vote across the whole report

We already have $v$ (**vote_count**) and $R$ (**vote_average**) and $C$ can be calculated as
"""

C = movies_df['vote_average'].mean()
print(C)

m = movies_df['vote_count'].quantile(0.9)
print(m)

q_movies = movies_df.copy().loc[movies_df['vote_count'] >= m]
q_movies.shape

def weighted_rating(x, m=m, C=C):
    v = x['vote_count']
    R = x['vote_average']

    # Calculation based on the IMDB formula
    return (v/(v+m) * R) + (m/(m+v) * C)

# Define a new feature 'score' and calculate its value with `weighted_rating()`
q_movies['score'] = q_movies.apply(weighted_rating, axis=1)

#Sort movies based on score calculated above
q_movies = q_movies.sort_values('score', ascending=False)

#Print the top 15 movies
q_movies[['title', 'vote_count', 'vote_average', 'score']].head(10)

"""## Making Most High Rated Movies Plot"""

plt.figure(figsize=(12,4))
colors = plt.cm.get_cmap('Spectral', len(q_movies['title'].head(6)))
plt.barh(q_movies['title'].head(6),q_movies['score'].head(6), align='center',
        color=colors(range(len(q_movies['title'].head(6)))))
plt.gca().invert_yaxis()
plt.xlabel("Score Movies")
plt.title("Most High Rated Movies")

plt.show()

"""This graph shows the list of the highest rated movies. The movie The Shawshank Redemption has the highest score compared to other movies such as Fight Club, The Dark Knight, Pulp Fiction, Inception, and The Godfather. The score given indicates a positive assessment of the quality of the movie from the audience or critics."""

#Sort movies based on popularity score above
populer = movies_df.sort_values('popularity', ascending=False)

#Print the top 15 populer movies
populer['title'].head(10)

"""## Making Most Popular Movies Plot"""

plt.figure(figsize=(12,4))
colors = plt.cm.get_cmap('coolwarm', len(populer['title'].head(6)))
plt.barh(populer['title'].head(6),populer['popularity'].head(6), align='center',
        color=colors(range(len(populer['title'].head(6)))))
plt.gca().invert_yaxis()
plt.xlabel("Popularity")
plt.title("Most Popular Movies")

plt.show()

"""This graph depicts the movies with the highest level of popularity by audience. Minions leads in this category, followed by Interstellar, Deadpool, Guardians of the Galaxy, Mad Max: Fury Road, and Jurassic World. Popularity is measured based on factors such as viewership or reviews."""

#Sort movies based on most viewed
populer = movies_df.sort_values('runtime', ascending=False)

#Print the top 15 most viewed movies
populer['title'].head(10)

"""## Making Most Longer Movies Runtime Plot"""

plt.figure(figsize=(12,4))
colors = plt.cm.get_cmap('Set2', len(populer['title'].head(6)))
plt.barh(populer['title'].head(6),populer['runtime'].head(6), align='center',
        color=colors(range(len(populer['title'].head(6)))))
plt.gca().invert_yaxis()
plt.xlabel("Runtime Movies in minute")
plt.title("Most Longer Movies Runtime")

plt.show()

"""This graph displays the movies with the longest runtimes. The movie Carlos has the longest runtime, followed by The Company, Gettysburg, Cleopatra, Hamlet, and Emma. This information shows movies that have longer and more complex stories that take longer to tell.

# **Content Bassed Filtering**

In this recommender system the content of the movie (overview, cast, crew, keyword, tagline etc) is used to find its similarity with other movies. Then the movies that are most likely to be similar are recommended.

<a href="https://ibb.co.com/PCZ0Vf2"><img src="https://i.ibb.co.com/0Jjvzd0/content-based-filtering.jpg" alt="content-based-filtering" border="0"></a>

# **Make Plotting Content Description(Overview) Based Recommender**
"""

movies_df['overview'].head(5)

"""# **TF-IDF Vectorizer The Overview variabel**

In this step we change the strings data in variabel `Overview` into matriks with TF-IDF Vectorizer. Also we clearing the strings data like remove all stop words, replace NaN with an empty strings data, then after all we check the matrix shape.
"""

#Import TfIdfVectorizer from scikit-learn
from sklearn.feature_extraction.text import TfidfVectorizer

#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'
tfidf = TfidfVectorizer(stop_words='english')

#Replace NaN with an empty string
movies_df['overview'] = movies_df['overview'].fillna('')

#Construct the required TF-IDF matrix by fitting and transforming the data
tfidf_matrix = tfidf.fit_transform(movies_df['overview'])

#Output the shape of tfidf_matrix
tfidf_matrix.shape

# Converting tf-idf vector in matrix form with todense() function
tfidf_matrix.todense()

# Create a dataframe to view the tf-idf matrix
# Columns are filled with category movies
# Rows are filled with movie names

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf.get_feature_names_out(),
    index=movies_df.title
).sample(5, axis=1).sample(10, axis=0)

"""# **Modeling**

## **Linear Similarity with linear kernel**
Linear similarity is done by using `linear_kernel` in `tfidf_matrix` processing. Where with this method we can calculate the similarity between matrices/vectors. It can be defined using equations like the following:

$$
\text{Linear Similarity} = \mathbf{A} \cdot \mathbf{B} = {\sum_{i=1}^n A_i B_i}
$$
"""

# Import linear_kernel
from sklearn.metrics.pairwise import linear_kernel

# Compute the linear similarity matrix
linear_sim = linear_kernel(tfidf_matrix, tfidf_matrix)
linear_sim

# Create a dataframe from the linear_sim variable with rows and columns of movie names
linear_sim_df = pd.DataFrame(linear_sim, index=movies_df['title'], columns=movies_df['title'])
print('Shape:', linear_sim_df.shape)

# View the similarity matrix for each movies
linear_sim_df.sample(10, axis=1).sample(10, axis=0)

"""## **Recommended System Settings**"""

#Construct a reverse map of indices and movie titles
indices = pd.Series(movies_df.index, index=movies_df['title']).drop_duplicates()

# Function that takes in movie title as input and outputs most similar movies
def get_recommendations(title, linear_sim=linear_sim):
    # Get the index of the movie that matches the title
    idx = indices[title]

    # Get the pairwsie similarity scores of all movies with that movie
    sim_scores = list(enumerate(linear_sim[idx]))

    # Sort the movies based on the similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Get the scores of the 10 most similar movies
    sim_scores = sim_scores[1:11]

    # Get the movie indices
    movie_indices = [i[0] for i in sim_scores]

    # Return the top 10 most similar movies with genres
    recommendations = movies_df[['title', 'genres']].iloc[movie_indices]
    return recommendations

"""## **First Testing Recommended System with Linear Similiarity**"""

movies_df.loc[movies_df[['id', 'title', 'genres']].apply(lambda x: x.eq('Deadpool').any(), axis=1), ['id', 'title', 'genres']]

get_recommendations('Deadpool', linear_sim)

movies_df.loc[movies_df[['id', 'title', 'genres']].apply(lambda x: x.eq('Guardians of the Galaxy').any(), axis=1), ['id', 'title', 'genres']]

get_recommendations('Guardians of the Galaxy', linear_sim)

"""## **Improve The Model with Cotent Implement an Credits, Genres and Keywords Based Recommender**
It goes without saying that the quality of our recommender would be increased with the usage of better metadata. That is exactly what we are going to do in this section. We are going to build a recommender based on the following metadata: the 3 top actors, the director, related genres and the movie plot keywords.

From the cast, crew and keywords features, we need to extract the three most important actors, the director and the keywords associated with that movie. Right now, our data is present in the form of "stringified" lists , we need to convert it into a safe and usable structure
"""

# Parse the stringified features into their corresponding python objects
from ast import literal_eval

features = ['cast', 'crew', 'keywords', 'genres']
for feature in features:
    movies_df[feature] = movies_df[feature].apply(literal_eval)

# Get the director's name from the crew feature. If director is not listed, return NaN
def get_director(x):
    for i in x:
        if i['job'] == 'Director':
            return i['name']
    return np.nan

# Returns the list top 3 elements or entire list; whichever is more.
def get_list(x):
    if isinstance(x, list):
        names = [i['name'] for i in x]
        #Check if more than 3 elements exist. If yes, return only first three. If no, return entire list.
        if len(names) > 3:
            names = names[:3]
        return names

    #Return empty list in case of missing/malformed data
    return []

# Define new director, cast, genres and keywords features that are in a suitable form.
movies_df['director'] = movies_df['crew'].apply(get_director)

features = ['cast', 'keywords', 'genres']
for feature in features:
    movies_df[feature] = movies_df[feature].apply(get_list)

# Print the new features of the first 3 films
movies_df[['title', 'cast', 'director', 'keywords', 'genres']].head(5)

# Function to convert all strings to lower case and strip names of spaces
def clean_data(x):
    if isinstance(x, list):
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        #Check if director exists. If not, return empty string
        if isinstance(x, str):
            return str.lower(x.replace(" ", ""))
        else:
            return ''

# Apply clean_data function to your features.
features = ['cast', 'keywords', 'director', 'genres']

for feature in features:
    movies_df[feature] = movies_df[feature].apply(clean_data)

# A new soup column was created to incorporate important information (director, cast, keywords, and genres)
def create_soup(x):
    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])
movies_df['soup'] = movies_df.apply(create_soup, axis=1)

# Import CountVectorizer and create the count matrix
from sklearn.feature_extraction.text import CountVectorizer

count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(movies_df['soup'])

"""# **Cosine Similiarity**

The Cosine Similarity to calculate a numeric quantity that denotes the similarity between two movies. We use the cosine similarity score since it is independent of magnitude and is relatively easy and fast to calculate. Mathematically, it is defined as follows:

$$
\text{Cosine Similarity} = \cos(\theta) = \frac{\mathbf{A} \cdot \mathbf{B}}{\|\mathbf{A}\| \|\mathbf{B}\|} =
\frac{\sum_{i=1}^n A_i B_i}{\sqrt{\sum_{i=1}^n A_i^2} \sqrt{\sum_{i=1}^n B_i^2}}
$$
"""

# Compute the Cosine Similarity matrix based on the count_matrix
from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(count_matrix, count_matrix)

# Reset index of our main DataFrame and construct reverse mapping as before
movies_df = movies_df.reset_index()
indices = pd.Series(movies_df.index, index=movies_df['title'])

"""# **Evaluation**

## **Second Testing Recommended System**
We gonne calculate the recommender system precision follow as this equation below,

$$
\text{Recommender system precision:} \quad P = \frac{\# \text{ of our recommendations that are relevant}}{\# \text{ of items we recommended}}
$$
"""

movies_df.loc[movies_df[['id', 'title', 'genres']].apply(lambda x: x.eq('Deadpool').any(), axis=1), ['id', 'title', 'genres']]

get_recommendations('Deadpool', cosine_sim)

"""For Deadpool movie:

$$
\text{Recommender system precision:} = \frac{9}{10} = 0.9
$$

"""

movies_df.loc[movies_df[['id', 'title', 'genres']].apply(lambda x: x.eq('Guardians of the Galaxy').any(), axis=1), ['id', 'title', 'genres']]

get_recommendations('Guardians of the Galaxy', cosine_sim)

"""For Guardians of the Galaxy movie:

$$
\text{Recommender system precision:} = \frac{10}{10} = 1
$$

"""