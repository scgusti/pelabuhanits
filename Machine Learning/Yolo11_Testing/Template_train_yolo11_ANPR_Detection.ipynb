{"cells":[{"cell_type":"markdown","metadata":{"id":"oe9vkEvFABbN"},"source":["[![Roboflow Notebooks](https://media.roboflow.com/notebooks/template/bannertest2-2.png?ik-sdk-version=javascript-1.4.3&updatedAt=1672932710194)](https://github.com/roboflow/notebooks)\n","\n","# How to Train YOLO11 Object Detection on a Custom Dataset\n","\n","---\n","\n","[![GitHub](https://badges.aleen42.com/src/github.svg)](https://github.com/ultralytics/ultralytics)\n","\n","YOLO11 builds on the advancements introduced in YOLOv9 and YOLOv10 earlier this year, incorporating improved architectural designs, enhanced feature extraction techniques, and optimized training methods.\n","\n","YOLO11m achieves a higher mean mAP score on the COCO dataset while using 22% fewer parameters than YOLOv8m, making it computationally lighter without sacrificing performance.\n","\n","YOLOv11 is available in 5 different sizes, ranging from `2.6M` to `56.9M` parameters, and capable of achieving from `39.5` to `54.7` mAP on the COCO dataset."]},{"cell_type":"markdown","metadata":{"id":"eO4jp3hX8dhj"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"gfvTJ0-ejc33"},"source":["### Configure API keys\n","\n","To fine-tune YOLO11, you need to provide your Roboflow API key. Follow these steps:\n","\n","- Go to your [`Roboflow Settings`](https://app.roboflow.com/settings/api) page. Click `Copy`. This will place your private key in the clipboard.\n","- In Colab, go to the left pane and click on `Secrets` (ðŸ”‘). Store Roboflow API Key under the name `ROBOFLOW_API_KEY`."]},{"cell_type":"markdown","metadata":{"id":"FyRdDYkqAKN4"},"source":["### Before you start\n","\n","Let's make sure that we have access to GPU. We can use `nvidia-smi` command to do that. In case of any problems navigate to `Edit` -> `Notebook settings` -> `Hardware accelerator`, set it to `GPU`, and then click `Save`."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y8cDtxLIBHgQ","outputId":"eab3b83b-289a-43b6-8803-455936e3afe6","executionInfo":{"status":"ok","timestamp":1734867109517,"user_tz":-420,"elapsed":1042,"user":{"displayName":"Fauzan Ariyatmoko","userId":"03907839304580209433"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Dec 22 11:31:48 2024       \n","+---------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n","|-----------------------------------------+----------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                      |               MIG M. |\n","|=========================================+======================+======================|\n","|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n","| N/A   61C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n","|                                         |                      |                  N/A |\n","+-----------------------------------------+----------------------+----------------------+\n","                                                                                         \n","+---------------------------------------------------------------------------------------+\n","| Processes:                                                                            |\n","|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n","|        ID   ID                                                             Usage      |\n","|=======================================================================================|\n","|  No running processes found                                                           |\n","+---------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"fcvTRlHH8n5V"},"source":["**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CjpPg4mGKc1v","outputId":"af0e160f-4fbd-4d2f-e112-0e363244306b","executionInfo":{"status":"ok","timestamp":1734867111140,"user_tz":-420,"elapsed":1271,"user":{"displayName":"Fauzan Ariyatmoko","userId":"03907839304580209433"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["import os\n","HOME = os.getcwd()\n","print(HOME)"]},{"cell_type":"markdown","metadata":{"id":"3C3EO_2zNChu"},"source":["## Install YOLO11 via Ultralytics"]},{"cell_type":"code","source":["!pip list | grep torch"],"metadata":{"id":"9kle0ABbrgew","outputId":"1a69255a-e0e6-4516-a209-6f46ffc4b866","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734867111140,"user_tz":-420,"elapsed":3,"user":{"displayName":"Fauzan Ariyatmoko","userId":"03907839304580209433"}}},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["torch                              2.5.1+cu121\n","torchaudio                         2.5.1+cu121\n","torchsummary                       1.5.1\n","torchvision                        0.20.1+cu121\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/ultralytics\n","%cd ultralytics\n","!pip install -q ."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ysPhAppB3NQw","executionInfo":{"status":"ok","timestamp":1734867124742,"user_tz":-420,"elapsed":13604,"user":{"displayName":"Fauzan Ariyatmoko","userId":"03907839304580209433"}},"outputId":"0a449238-46f5-43d2-c0d8-0e91b53de283"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ultralytics'...\n","remote: Enumerating objects: 45832, done.\u001b[K\n","remote: Counting objects: 100% (731/731), done.\u001b[K\n","remote: Compressing objects: 100% (434/434), done.\u001b[K\n","remote: Total 45832 (delta 583), reused 305 (delta 297), pack-reused 45101 (from 5)\u001b[K\n","Receiving objects: 100% (45832/45832), 39.13 MiB | 23.92 MiB/s, done.\n","Resolving deltas: 100% (33934/33934), done.\n","/content/ultralytics\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for ultralytics (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tdSMcABDNKW-","outputId":"f2acd3c7-5d9f-4daf-b1d8-4bde8fe414b3","executionInfo":{"status":"ok","timestamp":1734867141089,"user_tz":-420,"elapsed":16350,"user":{"displayName":"Fauzan Ariyatmoko","userId":"03907839304580209433"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.53 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete âœ… (2 CPUs, 12.7 GB RAM, 32.8/112.6 GB disk)\n"]}],"source":["%pip install \"ultralytics<=8.3.40\" supervision roboflow\n","import ultralytics\n","ultralytics.checks()"]},{"cell_type":"markdown","metadata":{"id":"oSI-qYxsG6Wl"},"source":["## Fine-tune YOLO11 on custom dataset"]},{"cell_type":"markdown","metadata":{"id":"YGOP0bCgH4cb"},"source":["**NOTE:** When training YOLOv11, make sure your data is located in `datasets`. If you'd like to change the default location of the data you want to use for fine-tuning, you can do so through Ultralytics' `settings.json`. In this tutorial, we will use one of the [datasets](https://universe.roboflow.com/liangdianzhong/-qvdww) available on [Roboflow Universe](https://universe.roboflow.com/). When downloading, make sure to select the `yolov11` export format."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BSd93ZJzZZKt","outputId":"5798fd15-69df-4e6e-a81b-4de86a7eeafd","executionInfo":{"status":"ok","timestamp":1734867151692,"user_tz":-420,"elapsed":10606,"user":{"displayName":"Fauzan Ariyatmoko","userId":"03907839304580209433"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/datasets\n","loading Roboflow workspace...\n","loading Roboflow workspace...\n","loading Roboflow project...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in License-Number-1 to yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 129745/129745 [00:04<00:00, 30177.12it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to License-Number-1 in yolov11:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3536/3536 [00:01<00:00, 1939.97it/s]\n"]}],"source":["!mkdir {HOME}/datasets\n","%cd {HOME}/datasets\n","\n","from google.colab import userdata\n","from roboflow import Roboflow\n","\n","ROBOFLOW_API_KEY = userdata.get('ROBOFLOW_API_KEY')\n","rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n","\n","workspace = rf.workspace(\"liangdianzhong\")\n","project = rf.workspace(\"project-oo3i7\").project(\"license-number-2x9cc\")\n","version = project.version(1)\n","dataset = version.download(\"yolov11\")"]},{"cell_type":"markdown","metadata":{"id":"YUjFBKKqXa-u"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2YkphuiaE7_","outputId":"abcfd253-36e9-4403-c5fb-dc7d3b03dcb8","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n","100% 5.35M/5.35M [00:00<00:00, 87.5MB/s]\n","New https://pypi.org/project/ultralytics/8.3.53 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n","Ultralytics 8.3.40 ðŸš€ Python-3.10.12 torch-2.5.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/content/datasets/License-Number-1/data.yaml, epochs=100, time=None, patience=100, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/ultralytics/runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 17.8MB/s]\n","Overriding model.yaml nc=80 with nc=1\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n","  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n","  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n","  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n","  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n"," 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n"," 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n"," 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n"," 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n"," 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n","YOLO11n summary: 319 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n","\n","Transferred 448/499 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/ultralytics/runs/detect/train', view at http://localhost:6006/\n","Freezing layer 'model.23.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/License-Number-1/train/labels... 1232 images, 1 backgrounds, 0 corrupt: 100% 1232/1232 [00:00<00:00, 1852.28it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/License-Number-1/train/labels.cache\n","/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.23 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n","  check_for_updates()\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, num_output_channels=3, method='weighted_average'), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/License-Number-1/valid/labels... 268 images, 0 backgrounds, 0 corrupt: 100% 268/268 [00:00<00:00, 999.88it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/License-Number-1/valid/labels.cache\n","Plotting labels to /content/ultralytics/runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n","Image sizes 640 train, 640 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/ultralytics/runs/detect/train\u001b[0m\n","Starting training for 100 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      1/100      9.54G      1.255      3.267      1.259         30        640: 100% 20/20 [00:22<00:00,  1.14s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:07<00:00,  2.48s/it]\n","                   all        268        271    0.00485      0.856      0.669      0.358\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      2/100      8.71G      1.255       1.98      1.155         35        640: 100% 20/20 [00:19<00:00,  1.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.13s/it]\n","                   all        268        271       0.56     0.0282     0.0694     0.0376\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      3/100       8.8G      1.299       1.75      1.196         32        640: 100% 20/20 [00:21<00:00,  1.06s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.10s/it]\n","                   all        268        271     0.0524     0.0369     0.0235     0.0124\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      4/100       8.8G      1.363      1.604      1.241         23        640: 100% 20/20 [00:19<00:00,  1.01it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.12s/it]\n","                   all        268        271     0.0728      0.114     0.0294     0.0148\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      5/100      8.71G      1.387       1.45       1.28         26        640: 100% 20/20 [00:21<00:00,  1.06s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.05it/s]\n","                   all        268        271   0.000933      0.277    0.00563    0.00246\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      6/100       8.8G      1.392      1.279      1.268         33        640: 100% 20/20 [00:19<00:00,  1.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.02it/s]\n","                   all        268        271   7.49e-05     0.0221   3.83e-05    1.9e-05\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      7/100      8.73G      1.359      1.169      1.237         23        640: 100% 20/20 [00:20<00:00,  1.04s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.06it/s]\n","                   all        268        271     0.0618     0.0775     0.0149    0.00674\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      8/100      8.77G      1.341      1.091      1.238         25        640: 100% 20/20 [00:19<00:00,  1.02it/s]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:03<00:00,  1.20s/it]\n","                   all        268        271      0.271      0.303      0.174     0.0841\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      9/100       8.8G      1.355      1.065      1.239         29        640: 100% 20/20 [00:20<00:00,  1.04s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.04it/s]\n","                   all        268        271      0.555      0.561      0.552      0.292\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","     10/100      8.67G      1.333      1.018       1.24        119        640:  90% 18/20 [00:18<00:02,  1.00s/it]"]}],"source":["%cd {HOME}\n","\n","!yolo task=detect mode=train model=yolo11n.pt data={dataset.location}/data.yaml epochs=100 batch=64 imgsz=640 plots=True"]},{"cell_type":"markdown","metadata":{"id":"3mkT-rUhqQLp"},"source":["**NOTE:** The results of the completed training are saved in `{HOME}/runs/detect/train/`. Let's examine them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1MScstfHhArr"},"outputs":[],"source":["!ls {HOME}/ultralytics/runs/detect/train/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_J35i8Ofhjxa"},"outputs":[],"source":["from IPython.display import Image as IPyImage\n","\n","IPyImage(filename=f'{HOME}/ultralytics/runs/detect/train/confusion_matrix.png', width=1280)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-urTWUkhRmn"},"outputs":[],"source":["from IPython.display import Image as IPyImage\n","\n","IPyImage(filename=f'{HOME}/ultralytics/runs/detect/train/results.png', width=1280)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HI4nADCCj3F5"},"outputs":[],"source":["from IPython.display import Image as IPyImage\n","\n","IPyImage(filename=f'{HOME}/ultralytics/runs/detect/train/val_batch0_pred.jpg', width=1280)"]},{"cell_type":"code","source":["from IPython.display import Image as IPyImage\n","\n","IPyImage(filename=f'{HOME}/ultralytics/runs/detect/train/P_curve.png', width=1280)"],"metadata":{"id":"FP5jAq7Q_zDL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from IPython.display import Image as IPyImage\n","\n","IPyImage(filename=f'{HOME}/ultralytics/runs/detect/train/R_curve.png', width=1280)"],"metadata":{"id":"Eopq57MtAAYg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ODk1VTlevxn"},"source":["## Validate fine-tuned model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YpyuwrNlXc1P"},"outputs":[],"source":["!yolo task=detect mode=val model={HOME}/ultralytics/runs/detect/train/weights/best.pt data={dataset.location}/data.yaml"]},{"cell_type":"markdown","source":["# Save the model into pt"],"metadata":{"id":"yi92jWGDxqnC"}},{"cell_type":"code","source":["# Save the best model weights to a specified location\n","best_model_path = os.path.join(HOME, 'ultralytics/runs/detect/train/weights/best.pt')\n","save_path = os.path.join(HOME, 'best_model.pt') # Change to your desired save location\n","!cp {best_model_path} {save_path}\n","\n","print(f\"Best model saved to: {save_path}\")"],"metadata":{"id":"VHmux29fwBKR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Convert pt file into ONNX Format Model saved"],"metadata":{"id":"F7olwtJVxhzy"}},{"cell_type":"code","source":["!pip install onnx\n","!pip install onnxruntime\n","!pip install ultralytics"],"metadata":{"id":"WNrjZfzCwXB1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# Load the YOLO11 model\n","model = YOLO(\"/content/best_model.pt\")\n","\n","# Export the model to ONNX format\n","model.export(format=\"onnx\")  # creates 'yolo11n.onnx'"],"metadata":{"id":"hjiXFftX0gSX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ultralytics import YOLO\n","\n","# Load the YOLO11 model\n","model = YOLO(\"/content/best_model.pt\")\n","\n","# Export the model to ONNX format\n","model.export(format=\"tflite\")  # creates 'yolo11n.onnx'"],"metadata":{"id":"fc1I0iaS1Id5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Image Testing Model"],"metadata":{"id":"iW0HH53GLeui"}},{"cell_type":"code","source":["!pip install easyocr\n","from google.colab.patches import cv2_imshow\n","import cv2\n","import easyocr\n","import matplotlib.pyplot as plt\n","from ultralytics import YOLO\n","import os\n","import csv\n","from datetime import datetime"],"metadata":{"id":"T1gT-PTuKBcR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize EasyOCR reader\n","reader = easyocr.Reader(['en', 'id'])  # Include 'id' for Indonesian license plates\n","\n","# Create output directory for captured images\n","output_dir = \"captured_plates\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Create or open the CSV file to store number plate data\n","csv_file = \"number_plate_data.csv\"\n","fieldnames = [\"Timestamp\", \"Plate Number\", \"Image Path\"]\n","\n","# Check if the CSV file exists, if not create it and write headers\n","if not os.path.exists(csv_file):\n","    with open(csv_file, mode='w', newline='') as file:\n","        writer = csv.DictWriter(file, fieldnames=fieldnames)\n","        writer.writeheader()\n","\n","\n","def predict_and_extract_text(image_path):\n","    # Read the image using cv2\n","    img = cv2.imread(image_path)\n","\n","    # Perform inference using YOLOv8\n","    model = YOLO(\"/content/best_model.pt\")  # Load the model here\n","    results = model(img)\n","\n","    # Get the first detection (assuming only one license plate)\n","    detection = results[0]\n","\n","    # Get bounding box coordinates\n","    if detection.boxes.xyxy.shape[0] > 0:  # Check if any boxes are detected\n","        x1, y1, x2, y2 = map(int, detection.boxes.xyxy[0])\n","\n","        # Crop the number plate region from the image\n","        cropped_image = img[y1:y2, x1:x2]\n","\n","        # --- Enhancements ---\n","        # 1. Preprocess the cropped image:\n","        gray = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n","        enhanced = cv2.equalizeHist(gray)  # Apply histogram equalization\n","        # You can add other enhancements here, like sharpening or denoising if needed\n","\n","        # 2. Perform OCR with character whitelist and other parameters:\n","        results_ocr = reader.readtext(\n","            enhanced,\n","            allowlist='ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789',  # Whitelist alphanumeric characters\n","            batch_size=45,\n","            detail=80,\n","            paragraph=False,\n","\n","        )\n","\n","        # Process detections and save data\n","        for (bbox, text, prob) in results_ocr:\n","            if prob > 0.8:  # Filter detections based on confidence\n","                (top_left, top_right, bottom_right, bottom_left) = bbox\n","                top_left = tuple(map(int, top_left))\n","                bottom_right = tuple(map(int, bottom_right))\n","\n","                # Draw bounding box and annotate text on the original image\n","                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 640, 0), 2)\n","                cv2.putText(img, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 640, 0), 2)\n","\n","                # Save captured image and data\n","                timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n","                image_filename = f\"{output_dir}/plate_{timestamp}.jpg\"\n","                cv2.imwrite(image_filename, img)  # Save the original image with bounding box\n","\n","                # Append data to CSV\n","                with open(csv_file, mode='a', newline='') as file:\n","                    writer = csv.DictWriter(file, fieldnames=fieldnames)\n","                    writer.writerow({\"Timestamp\": timestamp, \"Plate Number\": text, \"Image Path\": image_filename})\n","\n","                print(f\"Detected Plate: {text} | Confidence: {prob:.2f} | Saved: {image_filename}\")\n","\n","                # Display the original image with bounding box and text using matplotlib\n","                fig, ax = plt.subplots(1, 1, figsize=(10, 10))  # Adjust figsize as needed\n","                ax.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","                ax.set_title(\"Detected License Plate (Full Image)\")\n","                plt.show()\n","    else:\n","        print(\"No license plate detected in the image.\")\n","\n","\n","# Example usage\n","image_path = '/content/Plat-H-Semarang.jpg'  # Replace with the path to your image\n","predict_and_extract_text(image_path)"],"metadata":{"id":"71fTQyTyJYOQ"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}